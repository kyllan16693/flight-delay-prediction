{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee10791f-9ca0-4669-bf12-dd7a09c14e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f527a80-a193-4a52-9804-1c24ebd5769a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                  int64\n",
       "Quarter               int64\n",
       "Month                 int64\n",
       "DayofMonth            int64\n",
       "DayOfWeek             int64\n",
       "Origin                int64\n",
       "Dest                  int64\n",
       "CRSDepTime            int64\n",
       "CRSArrTime            int64\n",
       "Cancelled           float64\n",
       "Diverted            float64\n",
       "CRSElapsedTime      float64\n",
       "Distance            float64\n",
       "is_holiday_week       int64\n",
       "DepartureDensity    float64\n",
       "Visibility          float64\n",
       "WindSpeed           float64\n",
       "SevereWeather         int64\n",
       "BadWeather            int64\n",
       "DepDelay            float64\n",
       "delay_binary          int64\n",
       "delay_interval      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('csv_flight/df_nums.csv')\n",
    "# drop needless columns\n",
    "df = df.drop(columns = ['Tail_Number', 'Flight_Number_Reporting_Airline', 'OriginAirportSeqID', 'TotalDensity', \n",
    "                        'ArrivalDensity', 'OriginCityName', 'OriginState', 'DestAirportSeqID', 'DestCityName', 'DestState'])\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1decc60-54cd-43e4-965e-67c2300913ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# non-categorical columns to scale\n",
    "columns_to_scale = ['Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek', 'CRSDepTime', 'CRSArrTime', 'CRSElapsedTime', \n",
    "                    'Distance', 'DepartureDensity', 'Visibility', 'WindSpeed']\n",
    "scaler = StandardScaler()\n",
    "df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dec2f918-8ff6-414e-8842-2c1613a3535f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>CRSElapsedTime</th>\n",
       "      <th>Distance</th>\n",
       "      <th>is_holiday_week</th>\n",
       "      <th>DepartureDensity</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>SevereWeather</th>\n",
       "      <th>BadWeather</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>delay_binary</th>\n",
       "      <th>delay_interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.517272</td>\n",
       "      <td>-1.395768</td>\n",
       "      <td>-1.655277</td>\n",
       "      <td>-1.68001</td>\n",
       "      <td>-0.468058</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.431226</td>\n",
       "      <td>-1.514368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.410640</td>\n",
       "      <td>-0.599546</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.018231</td>\n",
       "      <td>0.334387</td>\n",
       "      <td>-0.724781</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.517272</td>\n",
       "      <td>-1.395768</td>\n",
       "      <td>-1.655277</td>\n",
       "      <td>-1.68001</td>\n",
       "      <td>-0.468058</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.230794</td>\n",
       "      <td>-1.302969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.272470</td>\n",
       "      <td>-0.521488</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.697870</td>\n",
       "      <td>0.334387</td>\n",
       "      <td>-0.724781</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.517272</td>\n",
       "      <td>-1.395768</td>\n",
       "      <td>-1.655277</td>\n",
       "      <td>-1.68001</td>\n",
       "      <td>-0.468058</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.216763</td>\n",
       "      <td>-1.332061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.610219</td>\n",
       "      <td>-0.753804</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.665834</td>\n",
       "      <td>0.334387</td>\n",
       "      <td>-0.724781</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.517272</td>\n",
       "      <td>-1.395768</td>\n",
       "      <td>-1.655277</td>\n",
       "      <td>-1.68001</td>\n",
       "      <td>-0.468058</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.010318</td>\n",
       "      <td>-0.965507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.938251</td>\n",
       "      <td>1.738485</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.640681</td>\n",
       "      <td>0.334387</td>\n",
       "      <td>-1.089562</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.517272</td>\n",
       "      <td>-1.395768</td>\n",
       "      <td>-1.655277</td>\n",
       "      <td>-1.68001</td>\n",
       "      <td>-0.468058</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.000297</td>\n",
       "      <td>-0.899566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.383465</td>\n",
       "      <td>2.095323</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.544573</td>\n",
       "      <td>0.334387</td>\n",
       "      <td>-1.089562</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year   Quarter     Month  DayofMonth  DayOfWeek  Origin  Dest  \\\n",
       "0 -1.517272 -1.395768 -1.655277    -1.68001  -0.468058       0     0   \n",
       "1 -1.517272 -1.395768 -1.655277    -1.68001  -0.468058       0     1   \n",
       "2 -1.517272 -1.395768 -1.655277    -1.68001  -0.468058       0     2   \n",
       "3 -1.517272 -1.395768 -1.655277    -1.68001  -0.468058       0     3   \n",
       "4 -1.517272 -1.395768 -1.655277    -1.68001  -0.468058       0     4   \n",
       "\n",
       "   CRSDepTime  CRSArrTime  Cancelled  Diverted  CRSElapsedTime  Distance  \\\n",
       "0   -1.431226   -1.514368        0.0       0.0       -0.410640 -0.599546   \n",
       "1   -1.230794   -1.302969        0.0       0.0       -0.272470 -0.521488   \n",
       "2   -1.216763   -1.332061        0.0       0.0       -0.610219 -0.753804   \n",
       "3   -1.010318   -0.965507        0.0       0.0        1.938251  1.738485   \n",
       "4   -1.000297   -0.899566        0.0       0.0        2.383465  2.095323   \n",
       "\n",
       "   is_holiday_week  DepartureDensity  Visibility  WindSpeed  SevereWeather  \\\n",
       "0                1         -2.018231    0.334387  -0.724781              0   \n",
       "1                1         -1.697870    0.334387  -0.724781              0   \n",
       "2                1         -1.665834    0.334387  -0.724781              0   \n",
       "3                1         -0.640681    0.334387  -1.089562              0   \n",
       "4                1         -0.544573    0.334387  -1.089562              0   \n",
       "\n",
       "   BadWeather  DepDelay  delay_binary  delay_interval  \n",
       "0           0      -3.0             0             NaN  \n",
       "1           0      -2.0             0             NaN  \n",
       "2           0       2.0             0             NaN  \n",
       "3           0      21.0             1             0.0  \n",
       "4           0      -2.0             0             NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d43f2474-7c07-40bb-979d-31e3b4d0fa87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1639428, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b9be24-4301-4662-90d4-d53f0a3d507f",
   "metadata": {},
   "source": [
    "#### Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "484d7b0e-842b-407a-839f-3d451887d166",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb597f50-f9e3-45bd-a2f3-21f9dca1983c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: torch.Size([1147599, 19])\n",
      "Shape of X_val: torch.Size([245914, 19])\n",
      "Shape of X_test: torch.Size([245915, 19])\n",
      "Shape of y_train: torch.Size([1147599])\n",
      "Shape of y_val: torch.Size([245914])\n",
      "Shape of y_test: torch.Size([245915])\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, 0:19].values\n",
    "y = df.iloc[:, 20].values\n",
    "\n",
    "# create 70% traning, 15% validation, 15% test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=123)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=123)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_val:\", X_val.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_val:\", y_val.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a02907fd-af05-4dc6-99dd-e6f150fa5a67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size=1, num_hidden_layers=5):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # first layer\n",
    "        layers = [nn.Linear(input_size, hidden_size)]\n",
    "        nn.init.kaiming_normal_(layers[-1].weight, nonlinearity='leaky_relu')\n",
    "        \n",
    "        for _ in range(num_hidden_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            nn.init.kaiming_normal_(layers[-1].weight, nonlinearity='leaky_relu')\n",
    "            layers.append(nn.BatchNorm1d(hidden_size))\n",
    "            layers.append(nn.Dropout(0.5))\n",
    "        \n",
    "        # output layer\n",
    "        layers.append(nn.Linear(hidden_size, output_size))\n",
    "        \n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers[:-1]:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                x = layer(x)\n",
    "                x = F.leaky_relu(x, 0.01) \n",
    "            else:\n",
    "                x = layer(x)\n",
    "        x = self.layers[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "055134a1-9ffc-4ba5-bbe9-c507f66b17c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SimpleNN(input_size=19, hidden_size=64).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=40)\n",
    "loss_function = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdbf84e2-eef0-42b3-ba0b-7d21a3ddf9fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.7472, Train Accuracy: 52.59%, Val Loss: 0.5670, Val Accuracy: 80.09%\n",
      "Epoch 201, Train Loss: 0.4653, Train Accuracy: 80.36%, Val Loss: 0.4634, Val Accuracy: 80.32%\n",
      "Epoch 401, Train Loss: 0.4608, Train Accuracy: 80.43%, Val Loss: 0.4605, Val Accuracy: 80.36%\n",
      "Epoch 601, Train Loss: 0.4602, Train Accuracy: 80.48%, Val Loss: 0.4590, Val Accuracy: 80.42%\n",
      "Epoch 801, Train Loss: 0.4579, Train Accuracy: 80.55%, Val Loss: 0.4580, Val Accuracy: 80.45%\n",
      "Epoch 1001, Train Loss: 0.4574, Train Accuracy: 80.56%, Val Loss: 0.4576, Val Accuracy: 80.49%\n",
      "Epoch 1201, Train Loss: 0.4569, Train Accuracy: 80.59%, Val Loss: 0.4574, Val Accuracy: 80.50%\n",
      "Epoch 1401, Train Loss: 0.4569, Train Accuracy: 80.59%, Val Loss: 0.4571, Val Accuracy: 80.53%\n",
      "Epoch 1601, Train Loss: 0.4567, Train Accuracy: 80.58%, Val Loss: 0.4572, Val Accuracy: 80.52%\n",
      "Epoch 1801, Train Loss: 0.4568, Train Accuracy: 80.59%, Val Loss: 0.4571, Val Accuracy: 80.52%\n",
      "Epoch 2001, Train Loss: 0.4566, Train Accuracy: 80.60%, Val Loss: 0.4572, Val Accuracy: 80.52%\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_features, train_labels, val_features, val_labels, optimizer, loss_function, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        train_outputs = model(train_features)\n",
    "        train_loss = loss_function(train_outputs.squeeze(), train_labels)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(val_features)\n",
    "            val_loss = loss_function(val_outputs.squeeze(), val_labels)\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        if epoch % 200 == 0:\n",
    "            train_predictions = torch.sigmoid(train_outputs).squeeze() > 0.5\n",
    "            train_correct = (train_predictions == train_labels).sum().item()\n",
    "            train_accuracy = train_correct / len(train_labels)\n",
    "\n",
    "            val_predictions = torch.sigmoid(val_outputs).squeeze() > 0.5\n",
    "            val_correct = (val_predictions == val_labels).sum().item()\n",
    "            val_accuracy = val_correct / len(val_labels)\n",
    "            \n",
    "            print(f'Epoch {epoch+1}, Train Loss: {train_loss.item():.4f}, Train Accuracy: {train_accuracy * 100:.2f}%, '\n",
    "                    f'Val Loss: {val_loss.item():.4f}, Val Accuracy: {val_accuracy * 100:.2f}%')\n",
    "\n",
    "train(model, X_train, y_train, X_val, y_val, optimizer, loss_function, epochs=2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87f4dbe8-b68e-4d70-9884-a7948f6e03fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4571, Test Accuracy: 80.59%\n"
     ]
    }
   ],
   "source": [
    "def test(model, test_features, test_labels, loss_function):\n",
    "    model.eval() \n",
    "    with torch.no_grad():  \n",
    "        test_outputs = model(test_features)\n",
    "        test_loss = loss_function(test_outputs.squeeze(), test_labels)\n",
    "        test_predictions = torch.sigmoid(test_outputs).squeeze() > 0.5\n",
    "        test_correct = (test_predictions == test_labels).sum().item()\n",
    "        test_accuracy = test_correct / len(test_labels)\n",
    "        \n",
    "    print(f'Test Loss: {test_loss.item():.4f}, Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "    \n",
    "test(model, X_test, y_test, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086baca8-9ab6-41e2-9107-c087aa222d5c",
   "metadata": {},
   "source": [
    "#### Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0681ca7-996b-4b70-bd09-86d69a4d4d8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e150a0d-84a7-4dd5-b5e5-b402b37f6643",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delay_interval\n",
      "0.0    119619\n",
      "1.0    100529\n",
      "2.0     68756\n",
      "3.0     32937\n",
      "4.0      3889\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(axis=0)\n",
    "print(df['delay_interval'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c284eac6-5b90-42ac-b6b0-7cae2df5c5c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#oversample the data to balance the classes\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "\n",
    "X = df.iloc[:, 0:19].values\n",
    "y = df.iloc[:, 21].values\n",
    "\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c301929d-3b16-42ab-a7c1-d1ddcc1e5179",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: torch.Size([228011, 19])\n",
      "Shape of X_val: torch.Size([48859, 19])\n",
      "Shape of X_test: torch.Size([48860, 19])\n",
      "Shape of y_train: torch.Size([228011])\n",
      "Shape of y_val: torch.Size([48859])\n",
      "Shape of y_test: torch.Size([48860])\n"
     ]
    }
   ],
   "source": [
    "# create 70% traning, 15% validation, 15% test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=123)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=123)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_val:\", X_val.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_val:\", y_val.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad537622-cd31-475e-b8ad-1ac331d17efd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size=1, num_hidden_layers=6):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # first layer\n",
    "        layers = [nn.Linear(input_size, hidden_size)]\n",
    "        nn.init.kaiming_normal_(layers[-1].weight, nonlinearity='leaky_relu')\n",
    "        \n",
    "        for _ in range(num_hidden_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            nn.init.kaiming_normal_(layers[-1].weight, nonlinearity='leaky_relu')\n",
    "            layers.append(nn.BatchNorm1d(hidden_size))\n",
    "            layers.append(nn.Dropout(0.5))\n",
    "        \n",
    "        # output layer\n",
    "        layers.append(nn.Linear(hidden_size, output_size))\n",
    "        \n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers[:-1]:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                x = layer(x)\n",
    "                x = F.leaky_relu(x, 0.01) \n",
    "            else:\n",
    "                x = layer(x)\n",
    "        x = self.layers[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f77c7a8b-848b-42ac-b536-4865b1c0e9c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SimpleNN(input_size=19, hidden_size=64, output_size=5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=40)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fce13f8f-e0a6-4ea8-9a28-721249c92d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.7509, Train Accuracy: 21.99%, Val Loss: 3.6980, Val Accuracy: 1.32%\n",
      "Epoch 301, Train Loss: 1.3226, Train Accuracy: 37.43%, Val Loss: 1.3238, Val Accuracy: 36.81%\n",
      "Epoch 601, Train Loss: 1.3174, Train Accuracy: 37.67%, Val Loss: 1.3218, Val Accuracy: 37.10%\n",
      "Epoch 901, Train Loss: 1.3157, Train Accuracy: 37.75%, Val Loss: 1.3222, Val Accuracy: 37.08%\n",
      "Epoch 1201, Train Loss: 1.3150, Train Accuracy: 37.74%, Val Loss: 1.3223, Val Accuracy: 37.09%\n",
      "Epoch 1501, Train Loss: 1.3151, Train Accuracy: 37.72%, Val Loss: 1.3222, Val Accuracy: 37.08%\n",
      "Epoch 1801, Train Loss: 1.3153, Train Accuracy: 37.71%, Val Loss: 1.3222, Val Accuracy: 37.08%\n",
      "Epoch 2101, Train Loss: 1.3150, Train Accuracy: 37.75%, Val Loss: 1.3223, Val Accuracy: 37.09%\n",
      "Epoch 2401, Train Loss: 1.3154, Train Accuracy: 37.76%, Val Loss: 1.3222, Val Accuracy: 37.09%\n",
      "Epoch 2701, Train Loss: 1.3149, Train Accuracy: 37.69%, Val Loss: 1.3223, Val Accuracy: 37.09%\n",
      "Epoch 3001, Train Loss: 1.3152, Train Accuracy: 37.73%, Val Loss: 1.3222, Val Accuracy: 37.09%\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_features, train_labels, val_features, val_labels, optimizer, loss_function, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        train_outputs = model(train_features)\n",
    "        train_loss = loss_function(train_outputs, train_labels)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(val_features)\n",
    "            val_loss = loss_function(val_outputs, val_labels)\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        if epoch % 300 == 0:\n",
    "            _, train_predictions = torch.max(train_outputs, 1)\n",
    "            train_correct = (train_predictions == train_labels).sum().item()\n",
    "            train_accuracy = train_correct / len(train_labels)\n",
    "            \n",
    "            _, val_predictions = torch.max(val_outputs, 1)\n",
    "            val_correct = (val_predictions == val_labels).sum().item()\n",
    "            val_accuracy = val_correct / len(val_labels)\n",
    "            print(f'Epoch {epoch+1}, Train Loss: {train_loss.item():.4f}, Train Accuracy: {train_accuracy * 100:.2f}%, '\n",
    "                    f'Val Loss: {val_loss.item():.4f}, Val Accuracy: {val_accuracy * 100:.2f}%')\n",
    "\n",
    "train(model, X_train, y_train, X_val, y_val, optimizer, loss_function, epochs=3001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "450b164d-5b21-49aa-8d60-d33b5486d81e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.3250, Test Accuracy: 37.47%\n"
     ]
    }
   ],
   "source": [
    "def test(model, test_features, test_labels, loss_function):\n",
    "    model.eval() \n",
    "    with torch.no_grad():  \n",
    "        test_outputs = model(test_features)\n",
    "        test_loss = loss_function(test_outputs, test_labels)\n",
    "        _, test_predictions = torch.max(test_outputs, 1)\n",
    "        test_correct = (test_predictions == test_labels).sum().item()\n",
    "        test_accuracy = test_correct / len(test_labels)\n",
    "        \n",
    "    print(f'Test Loss: {test_loss.item():.4f}, Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "    \n",
    "test(model, X_test, y_test, loss_function)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
